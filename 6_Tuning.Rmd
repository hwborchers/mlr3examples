---
title: "Tuning"
author: "Hans W. Borchers"
date: "July 2020"
output:
  html_document:
    css: "mlr3.css"
    keep_md: true
    toc: true
    toc_float:
      collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
library(mlr3verse, quietly = TRUE)
library(mlr3learners.c50)
```

We will use the same data and task as before.
```{r}
Glass <- RWeka::read.arff("glass.arff")

task <- TaskClassif$new(id = "glass",
                        backend = Glass, target = "Type")
```


## Hyperparameter tuning

The default of the number of small trees generated by the 'ranger' Random Forrest algorithm is 500. For a small data set this may be a much too big number of trees.

We will in *mlr3* determine an optimal number of trees through the "hyperparameter tuning" mechanism. First define the resampling method as before.
```{r}
cv5 = rsmp("cv", folds = 10)
```

```{r}
ps = ParamSet$new(list(
  ParamInt$new("num.trees", lower = 50, upper = 500))
)
```

```{r}
at = AutoTuner$new(
  learner = lrn("classif.ranger"),
  resampling = rsmp("cv", folds = 10),
  measures = msr("classif.acc"),
  tune_ps = ps,
  terminator = term("evals", n_evals = 20),
  tuner = TunerRandomSearch$new()
)
```

```{r}
resample(task = task,
         learner = at,
         resampling = rsmp("holdout"))
```


## Feature selection

### Filter-based

Filter methods assign an importance value to each feature. Based on these values the features can be ranked and selected for a feature subset.
```{r}
mlr_filters
```

Package *praznik* provides many information based variable importance measures, such as 'JMI' for "JointMutualInformation".
```{r}
# library(praznik)
filter = FilterJMI$new()
filter
```

Apply the filter to the task.
```{r}
filter$calculate(task)
filter$print()
```

Information gain id, e.g., implemented in *FSelectorRcpp*.
```{r}
library(FSelectorRcpp)
filter = FilterInformationGain$new()
filter
filter$calculate(task)
filter$print()
```

The problem with all these feature selection approaches is that they all return different scores and rankings.

[Multi-objective hyperparameter tuning and feature selection using filter ensembles](https://arxiv.org/pdf/1912.12912.pdf)


### Wrapper-based

For wrapper-based feature selection there is a new *mlr3fselect* package that will be on CRAN in short time.
```{r}
# remotes::install_github("mlr-org/mlr3fselect")
library(mlr3fselect)
```

We use the 'glass' data and the task as defined before.

```{r}
learner = lrn("classif.ranger")
resampling = rsmp("holdout")
measure = msr("classif.ce")
```

Next we define termination, an 'fselect' instance, random search for the 'fselector', and start the optimization. Possible 'terminators' (in package *bbotk) can be seen with `mlr_terminators`.

```{r}
# Define termination criterion
terminator = trm("evals", n_evals = 20)

# Create fselect instance
instance = FSelectInstanceSingleCrit$new(task = task,
  learner = learner,
  resampling = resampling,
  measure = measure,
  terminator = terminator)

# Load fselector
fselector = fs("random_search")

# Trigger optimization
fselector$optimize(instance)

# View results
instance$result
```


### Embedded

Some learners are capable to return to feature importance scores and a ranking based on their internal algorithm, for instance `rpart` or `ranger`, as we have seen above.
